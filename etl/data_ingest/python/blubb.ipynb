{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching dataset: demo_divcz\n",
      "         citizen freq geo        partner unit TIME_PERIOD OBS_VALUE OBS_FLAG\n",
      "0  EU27_2007_FOR    A  AT  EU27_2007_FOR   NR        2012       251      NaN\n",
      "1  EU27_2007_FOR    A  BG  EU27_2007_FOR   NR        2012         0      NaN\n",
      "2  EU27_2007_FOR    A  CH  EU27_2007_FOR   NR        2012       462      NaN\n",
      "3  EU27_2007_FOR    A  CZ  EU27_2007_FOR   NR        2012        41      NaN\n",
      "4  EU27_2007_FOR    A  DK  EU27_2007_FOR   NR        2012        95      NaN\n",
      "Data uploaded to Antigone successfully.\n",
      "Data uploaded to Ismene successfully.\n",
      "Data uploaded to Eteocles successfully.\n",
      "Data uploaded to Polyneices successfully.\n",
      "\n",
      "Fetching dataset: demo_divcb\n",
      "         c_birth freq geo        partner unit TIME_PERIOD OBS_VALUE\n",
      "0  EU27_2007_FOR    A  DK  EU27_2007_FOR   NR        2012       110\n",
      "1  EU27_2007_FOR    A  EE  EU27_2007_FOR   NR        2012         1\n",
      "2  EU27_2007_FOR    A  FI  EU27_2007_FOR   NR        2012        95\n",
      "3  EU27_2007_FOR    A  NO  EU27_2007_FOR   NR        2012       181\n",
      "4  EU27_2007_FOR    A  PT  EU27_2007_FOR   NR        2012        86\n",
      "Data uploaded to Antigone successfully.\n",
      "Data uploaded to Ismene successfully.\n",
      "Data uploaded to Eteocles successfully.\n",
      "Data uploaded to Polyneices successfully.\n",
      "\n",
      "Fetching dataset: demo_ndivind\n",
      "  freq geo indic_de TIME_PERIOD OBS_VALUE OBS_FLAG\n",
      "0    A  AL      DIV        1960       850      NaN\n",
      "1    A  AL      DIV        1961      1314      NaN\n",
      "2    A  AL      DIV        1962      1236      NaN\n",
      "3    A  AL      DIV        1963      1046      NaN\n",
      "4    A  AL      DIV        1964      1104      NaN\n",
      "Data uploaded to Antigone successfully.\n",
      "Data uploaded to Ismene successfully.\n",
      "Data uploaded to Eteocles successfully.\n",
      "Data uploaded to Polyneices successfully.\n",
      "\n",
      "Fetching dataset: tps00014\n",
      "  freq geo  indic_de TIME_PERIOD OBS_VALUE OBS_FLAG\n",
      "0    A  AM  FAGEMAR1        2015      26.8      NaN\n",
      "1    A  AM  FAGEMAR1        2017      26.7      NaN\n",
      "2    A  AM  FAGEMAR1        2018      26.7      NaN\n",
      "3    A  AT  FAGEMAR1        2011      30.3      NaN\n",
      "4    A  AT  FAGEMAR1        2012      30.6      NaN\n",
      "Data uploaded to Antigone successfully.\n",
      "Data uploaded to Ismene successfully.\n",
      "Data uploaded to Eteocles successfully.\n",
      "Data uploaded to Polyneices successfully.\n",
      "\n",
      "Fetching dataset: tps00216\n",
      "  freq geo indic_de TIME_PERIOD OBS_VALUE OBS_FLAG\n",
      "0    A  AL   GDIVRT        2014       1.5      NaN\n",
      "1    A  AL   GDIVRT        2015       1.3      NaN\n",
      "2    A  AL   GDIVRT        2016       1.9      NaN\n",
      "3    A  AL   GDIVRT        2017       1.6      NaN\n",
      "4    A  AL   GDIVRT        2018       1.7      NaN\n",
      "Data uploaded to Antigone successfully.\n",
      "Data uploaded to Ismene successfully.\n",
      "Data uploaded to Eteocles successfully.\n",
      "Data uploaded to Polyneices successfully.\n",
      "\n",
      "Fetching dataset: tps00206\n",
      "  freq geo indic_de TIME_PERIOD OBS_VALUE OBS_FLAG\n",
      "0    A  AD   GNUPRT        2012       3.7      NaN\n",
      "1    A  AD   GNUPRT        2018       3.9      NaN\n",
      "2    A  AL   GNUPRT        2013       8.2      NaN\n",
      "3    A  AL   GNUPRT        2014       8.2      NaN\n",
      "4    A  AL   GNUPRT        2015       8.7      NaN\n",
      "Data uploaded to Antigone successfully.\n",
      "Data uploaded to Ismene successfully.\n",
      "Data uploaded to Eteocles successfully.\n",
      "Data uploaded to Polyneices successfully.\n",
      "Total script runtime: 6.75908350944519 seconds\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import psycopg2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from lxml import etree\n",
    "import time\n",
    "\n",
    "# Load environment variables (should be identical to other scripts)\n",
    "load_dotenv()\n",
    "\n",
    "# Define the database configurations for each environment\n",
    "db_configs = [\n",
    "    {\n",
    "        'dbname': 'Antigone',\n",
    "        'user': os.getenv('DB_USER', 'DB_USER'),\n",
    "        'password': os.getenv('DB_PASSWORD', 'DB_PASSWORD'),\n",
    "        'host': os.getenv('DB_HOST', 'DB_HOST'),\n",
    "        'schema': 'Source'\n",
    "    },\n",
    "    {\n",
    "        'dbname': 'Ismene',\n",
    "        'user': os.getenv('DB_USER', 'DB_USER'),\n",
    "        'password': os.getenv('DB_PASSWORD', 'DB_PASSWORD'),\n",
    "        'host': os.getenv('DB_HOST', 'DB_HOST'),\n",
    "        'schema': 'Source'\n",
    "    },\n",
    "    {\n",
    "        'dbname': 'Eteocles',\n",
    "        'user': os.getenv('DB_USER', 'DB_USER'),\n",
    "        'password': os.getenv('DB_PASSWORD', 'DB_PASSWORD'),\n",
    "        'host': os.getenv('DB_HOST', 'DB_HOST'),\n",
    "        'schema': 'Source'\n",
    "    },\n",
    "    {\n",
    "        'dbname': 'Polyneices',\n",
    "        'user': os.getenv('DB_USER', 'DB_USER'),\n",
    "        'password': os.getenv('DB_PASSWORD', 'DB_PASSWORD'),\n",
    "        'host': os.getenv('DB_HOST', 'DB_HOST'),\n",
    "        'schema': 'Source'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to fetch and parse XML data from Eurostat API\n",
    "def fetch_eurostat_data(dataset_code):\n",
    "    url = f\"https://ec.europa.eu/eurostat/api/dissemination/sdmx/3.0/data/dataflow/ESTAT/{dataset_code}/1.0?compress=false\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {dataset_code}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    root = etree.fromstring(response.content)\n",
    "    structured_data = []\n",
    "    for series in root.findall('.//Series', namespaces={}):\n",
    "        series_data = series.attrib\n",
    "        for obs in series.findall('.//Obs', namespaces={}):\n",
    "            obs_data = obs.attrib\n",
    "            record = {**series_data, **obs_data}\n",
    "            structured_data.append(record)\n",
    "\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    if df.empty:\n",
    "        print(\"DataFrame is empty, please check the XML structure or namespace.\")\n",
    "    else:\n",
    "        print(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to upload data to PostgreSQL\n",
    "def upload_to_postgres(df, table_name, config):\n",
    "    engine = create_engine(f'postgresql://{config[\"user\"]}:{config[\"password\"]}@{config[\"host\"]}/{config[\"dbname\"]}')\n",
    "    df.columns = [col.replace(' ', '_').lower() for col in df.columns]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.to_sql(table_name, engine, schema=config['schema'], if_exists='replace', index=False, chunksize=500)\n",
    "    print(f\"Data uploaded to {config['dbname']} successfully.\")\n",
    "\n",
    "# Dataset mapping to table names\n",
    "dataset_mapping = {\n",
    "\n",
    "    'demo_divcz': 'divorces_by_citizenship_of_wife_and_husband',\n",
    "    'demo_divcb': 'divorces_by_country_of_birth_of_wife_and_husband',\n",
    "    'demo_ndivind': 'divorce_indicators',\n",
    "    'tps00014': 'mean_age_at_first_marriage_by_sex',\n",
    "    'tps00216': 'crude_divorce_rate',\n",
    "    'tps00206': 'crude_marriage_rate'\n",
    "\n",
    "}\n",
    "\n",
    "# Main function to orchestrate data ingestion\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    for dataset_code, table_name in dataset_mapping.items():\n",
    "        print(f\"\\nFetching dataset: {dataset_code}\")\n",
    "        data = fetch_eurostat_data(dataset_code)\n",
    "        if data is not None:\n",
    "            for config in db_configs:\n",
    "                upload_to_postgres(data, table_name, config)\n",
    "\n",
    "    # Calculate runtime\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    print(f\"Total script runtime: {runtime} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
